{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Table of Contents**\n",
    "1. Introduction\n",
    "2. Pipeline Input Parameters\n",
    "3. Preprocessing\n",
    "4. Training\n",
    "5. Evaluation\n",
    "6. Register Model\n",
    "7. Accuracy Condition Step\n",
    "8. Pipeline Creation\n",
    "9. Make New Model From the Already Existing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **I. Introduction**\n",
    "In this stage, we will initialize some important variables. Most of these variables are variables that needed to be initialized in order for SageMaker to be able to run. Beside of that, there are some variables that are best to be initialized at the front so it will make the whole work structurally better. \n",
    "\n",
    "First, we need to ensure that the latest version of SageMaker is installed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that newest sagemaker is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker --quiet # Ensure latest version of SageMaker is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.session.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Important Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = \"Hate-Speech-Classifier\"  # Model name in model registry\n",
    "prefix = \"sagemaker/HS-Classifier\"  # Prefix to S3 artifacts\n",
    "pipeline_name = \"HSPipeline\"  # SageMaker Pipeline name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_uri = session.upload_data(path=\"dataset/hate-speech-dataset.csv\",\n",
    "                                     bucket=bucket\n",
    "                                     key_prefix=prefix + \"/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Pipeline Input Parameters**\n",
    "Below are parameters that are initialized for pipeline. Later on, if we want to make a new model with newer dataset and new parameterss, we just need to run them in our pipeline code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=\"ml.m5.large\")\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "input_data = ParameterString(name=\"InputData\", default_value=input_data_uri)\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n",
    "\n",
    "epochs = ParameterInteger(name='Epochs', default_value=3)\n",
    "train_batch_size = ParameterInteger(name='TrainBatchSize', default_value=32)\n",
    "model_name = ParameterString(name='ModelName', default_value='bert-base-cased')\n",
    "training_instance_type = ParameterString(name='TrainingInstanceType', default_value='ml.p3.2xlarge')\n",
    "training_instance_count = ParameterInteger(name='TrainingInstanceCount', default_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Preprocessing**\n",
    "In this step, we preprocess the input dataset so it will be more suitable to be trained. We are doing this by using Scikit-Learn Processor, a preprocessing tool based on Scikit-Learn that are built within SageMaker. In order for this processor to work, we need to prepare a preprocessing script. In this step, we will divide the data into two groups, _train dataset_ and _validation dataset_. Train dataset will be used for training the model and validation dataset will be used for validating the quality of the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "# Create SKlearn processor object\n",
    "# The object contains information about what instance type to use, the IAM role to use etc.\n",
    "# A managed processor comes with a preconfigured container, so only specifying version is required.\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"processing-job\",\n",
    ")\n",
    "\n",
    "# Use the sklearn_processor in a Sagemaker pipelines ProcessingStep\n",
    "step_preprocess_data = ProcessingStep(\n",
    "    name=\"Preprocess-Data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\")],\n",
    "    \n",
    "    outputs=[ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\n",
    "                              destination=Join(on=\"/\", values=[\"s3://{}\".format(bucket),\n",
    "                                                               prefix, \n",
    "                                                               ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                                                               \"train\"])),\n",
    "             \n",
    "             ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\n",
    "                              destination=Join(on=\"/\", values=[\"s3://{}\".format(bucket),\n",
    "                                                               prefix,\n",
    "                                                               ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                                                               \"validation\"]))\n",
    "            ],\n",
    "    code=\"scripts/preprocess.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IV. Training**\n",
    "This is the Training Step, a step where we will use the _train dataset_ that we obtained from the previous step to train our model. We will use **Bert-Base-Cased** architecture for our model. Just like the previous step, we also need to prepare a python script to execute this step. We will use HuggingFace function that is built within SageMaker. There are some parameters that are included in our pipeline parameters. By doing this, we can change their values in the future to experiment then we can get the best model possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': epochs,\n",
    "                 'train_batch_size': train_batch_size,\n",
    "                 'model_name':model_name\n",
    "                 }\n",
    "huggingface_estimator = HuggingFace(entry_point='scripts/train.py',\n",
    "                                    instance_type=training_instance_type,\n",
    "                                    instance_count=training_instance_count,\n",
    "                                    role=role,\n",
    "                                    transformers_version='4.6',\n",
    "                                    pytorch_version='1.7',\n",
    "                                    py_version='py36',\n",
    "                                    hyperparameters = hyperparameters)\n",
    "\n",
    "step_train_model = TrainingStep(\n",
    "    name=\"Train-Model\",\n",
    "    estimator=huggingface_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **V. Evaluation**\n",
    "In this step, we will evaluate the quality of the model that we already obtained from the previous step. We will evaluate this model using _validation dataset_ that we obtained from preprocessing step. We will use Scikit-Learn Processor, the same type of processor that we used for preprocessing. Similar to two previous steps, we also need to prepare a python script to execute this step. The final product of this step is **Evaluation Report** that has the full report of our model's quality including its accuracy, precision, recall, and confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "evaluate_model_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={\"AWS_DEFAULT_REGION\": region},\n",
    "    max_runtime_in_seconds=7200,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# Use the evaluate_model_processor in a Sagemaker pipelines ProcessingStep.\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"Evaluate-Model\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_preprocess_data.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,  \n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"evaluation-report\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"scripts/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VI. Register Model**\n",
    "If the trained model meets the model performance requirements a new model version is registered with the model registry for further analysis. To attach model metrics to the model version, create a **Model Metrics** object using the evaluation report created in the evaluation step. Then, create the **Register Model** step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "                    \"S3Uri\"\n",
    "                ],\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Crete a RegisterModel step, which registers the model with Sagemaker Model Registry.\n",
    "step_register_model = RegisterModel(\n",
    "    name=\"Register-Model\",\n",
    "    estimator=huggingface_estimator,\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VII. Accuracy Condition Step**\n",
    "Adding conditions to the pipeline is done with a **Condition Step**. In this case, we only want to register the new model version with the model registry if the new model meets an accuracy condition. We can set the acccuracy condition based on our need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=0.7,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"Accuracy-Condition\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[step_register_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VIII. Pipeline Creation**\n",
    "Now with all steps exist, we can combine them all to make a pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_preprocess_data, step_train_model, step_evaluate_model, step_cond],\n",
    ")\n",
    "\n",
    "# Submit pipline\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Execute pipeline using the default parameters.\n",
    "execution = pipeline.start()\n",
    "\n",
    "execution.wait()\n",
    "\n",
    "# List the execution steps to check out the status and artifacts:\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IX. Make New Model From the Already Existing Pipeline**\n",
    "We can run this model if we have new dataset. When we know that we need new model to match the newest dataset, we can obtain a new model only by running below code because we already have a pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input_data_uri = session.upload_data(path=\"dataset/new-hate-speech-dataset.csv\",\n",
    "                                         bucket=bucket,\n",
    "                                         key_prefix=prefix + \"/new-data\")\n",
    "\n",
    "\n",
    "\n",
    "# Execute pipeline with explicit parameters\n",
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputData=new_input_data_uri,\n",
    "    )\n",
    ")\n",
    "\n",
    "execution.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
